{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.vision.gan import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should set the following option to True if the notebook isn't located in the file system inside a clone of the git repo (with the needed Python modules available) it belongs to; i.e., it's running independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_as_standalone_nb = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell needs to be executed before importing local project modules, like import core.gan\n",
    "if run_as_standalone_nb:\n",
    "    root_lib_path = os.path.abspath('generative-lab')\n",
    "    if not os.path.exists(root_lib_path):\n",
    "        !git clone https://github.com/davidleonfdez/generative-lab.git\n",
    "    if root_lib_path not in sys.path:\n",
    "        sys.path.insert(0, root_lib_path)\n",
    "else:\n",
    "    import local_lib_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local project modules. Must be imported after local_lib_import or cloning git repo.\n",
    "from core.biggan import biggan_disc_64, biggan_gen_64, BigGANItemList, BigGANGenImagesSampler\n",
    "from core.gan import GANGPLearner, GANLossArgs, GeneratorFuncStateLoader, save_gan_learner\n",
    "from core.layers import AvgFlatten\n",
    "from core.losses import hinge_adversarial_losses, loss_func_with_kernel_regularizer, OrthogonalRegularizer\n",
    "from core.gan_metrics import evaluate_models_fid, EvaluationItem, FIDCalculator\n",
    "from core.gen_utils import PrinterProgressTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point this variable to the path where you want to save your models\n",
    "models_root = Path('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "img_n_channels = 3\n",
    "batch_size = 128 # Std is 512-2048\n",
    "ch_mult = 32 # Std is 64-96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable occasional annoying warnings produced by libraries using pytorch, which \n",
    "# may collapse the output during data loading or training\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.nn.functional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `real_images_path` to the location of the dataset you want to work with.  If needed, as a previous step, fastai provides the method `untar_data` to download and extract a dataset from a remote URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_path = Path('/kaggle/input/celeba-dataset/img_align_celeba/')\n",
    "real_images_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, bs, size, noise_sz=100):\n",
    "    return (BigGANItemList.from_folder(path, noise_sz=noise_sz)\n",
    "               .split_none()\n",
    "               .label_from_func(noop)\n",
    "               .transform(tfms=[[crop_pad(size=size, row_pct=0.5, col_pct=0.5)], []], size=size, tfm_y=True)\n",
    "               .databunch(bs=bs)\n",
    "               .normalize(stats = [torch.tensor([0.5,0.5,0.5]), torch.tensor([0.5,0.5,0.5])], do_x=False, do_y=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(real_images_path, batch_size, img_size)\n",
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRITIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest method to build a BigGAN discriminator is:\n",
    "\n",
    "```\n",
    "biggan_disc_64(in_n_channels: int=3, ch_mult: int=96, **disc_kwargs)`\n",
    "```\n",
    "\n",
    "It creates an architecture with the same depth and feature maps as in the paper.\n",
    "\n",
    "The parameters `disc_kwargs` are passed through to `BigGANDiscriminator` constructor:\n",
    "\n",
    "```\n",
    "BigGANDiscriminator(in_sz: int, res_blocks_n_ftrs: List[Tuple[int, int]], \n",
    "                    idx_block_self_att: int, n_classes: int=1, \n",
    "                    down_op: core.layers.DownsamplingOperation2d=None, \n",
    "                    activ: nn.Module=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = biggan_disc_64(img_n_channels, ch_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return just one element per batch, as required by GAN loss management\n",
    "critic = nn.Sequential(critic, AvgFlatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest method to build a BigGAN generator is:\n",
    "\n",
    "```\n",
    "biggan_gen_64(out_n_channels: int=3, ch_mult: int=96, **gen_kwargs)\n",
    "```\n",
    "\n",
    "It creates an architecture with the same depth and feature maps as in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters `gen_kwargs` are passed through to `BigGANGenerator` constructor:\n",
    "\n",
    "```\n",
    "BigGANGenerator(out_sz: int, out_n_channels: int, up_blocks_n_ftrs: List[Tuple[int, int]], \n",
    "                z_split_sz: int=20, n_classes: int=1, class_embedding_sz: int=128, \n",
    "                up_op: core.layers.UpsamplingOperation2d=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = biggan_gen_64(img_n_channels, ch_mult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss, d_loss = hinge_adversarial_losses()\n",
    "g_loss_reg = loss_func_with_kernel_regularizer(g_loss, \n",
    "                                               OrthogonalRegularizer(generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_lambda = 0.1\n",
    "learner = GANGPLearner(data, generator, critic, GANLossArgs(g_loss, d_loss),\n",
    "                       opt_func=partial(optim.Adam, betas=(0.,0.999)), wd=0.,\n",
    "                       switch_eval=False, plambda=gp_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(10, lr)\n",
    "save_gan_learner(learner, models_root/'biggan-celeba-tr1-10ep.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.show_results(ds_type=DatasetType.Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator = FIDCalculator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids = ['1']\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total_imgs = 10000\n",
    "n_imgs_by_group = 500\n",
    "\n",
    "models = [EvaluationItem(model_id, biggan_gen_64, [img_n_channels, ch_mult], {})\n",
    "          for model_id in model_ids]\n",
    "\n",
    "def resolve_state_path(model_id:str):\n",
    "    return models_root/f'biggan-celeba-tr{model_id}-{n_epochs}ep.pth'\n",
    "\n",
    "results = evaluate_models_fid(models, data, GeneratorFuncStateLoader(resolve_state_path),\n",
    "                              n_total_imgs, n_imgs_by_group, calculator, PrinterProgressTracker(),\n",
    "                              BigGANGenImagesSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
