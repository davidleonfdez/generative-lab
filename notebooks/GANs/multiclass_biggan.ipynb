{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.vision.gan import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should set the following option to True if the notebook isn't located in the file system inside a clone of the git repo (with the needed Python modules available) it belongs to; i.e., it's running independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_as_standalone_nb = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell needs to be executed before importing local project modules, like import core.gan\n",
    "if run_as_standalone_nb:\n",
    "    root_lib_path = os.path.abspath('generative-lab')\n",
    "    if not os.path.exists(root_lib_path):\n",
    "        !git clone https://github.com/davidleonfdez/generative-lab.git\n",
    "    if root_lib_path not in sys.path:\n",
    "        sys.path.insert(0, root_lib_path)\n",
    "else:\n",
    "    import local_lib_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local project modules. Must be imported after local_lib_import or cloning git repo.\n",
    "from core.biggan import biggan_disc_64, biggan_gen_64, BigGANGenImagesSampler\n",
    "from core.data import BigGANItemList\n",
    "from core.gan import GANLossArgs, save_gan_learner, ConditionalGANLearner\n",
    "from core.losses import hinge_adversarial_losses, loss_func_with_kernel_regularizer, OrthogonalRegularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point this variable to the path where you want to save your models\n",
    "models_root = Path('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "img_n_channels = 3\n",
    "# Std bs is 512-2048\n",
    "batch_size = 16 \n",
    "# Std ch is 64-96\n",
    "ch_mult = 4     \n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable occasional annoying warnings produced by libraries using pytorch, which \n",
    "# may collapse the output during data loading or training\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.nn.functional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `real_images_path` to the location of the dataset you want to work with.  If needed, as a previous step, fastai provides the method `untar_data` to download and extract a dataset from a remote URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_path = untar_data(URLs.MNIST_TINY)/'train'\n",
    "real_images_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_cat(img_path:Path) -> str:\n",
    "    cat_name = img_path.resolve().parts[-2]\n",
    "    return cat_name\n",
    "\n",
    "def get_data(path, bs, size, n_classes, noise_sz=100):\n",
    "    return (BigGANItemList.from_folder(path, noise_sz=noise_sz, n_classes=n_classes)\n",
    "               .split_none()\n",
    "               .label_from_func(noop, resolve_cat_func=resolve_cat)\n",
    "               .transform(tfms=[[crop_pad(size=size, row_pct=0.5, col_pct=0.5)], []], size=size, tfm_y=True)\n",
    "               .databunch(bs=bs))\n",
    "               # The `normalize` method is not compatible with the labels (image + category). \n",
    "               # An equivalent normalization is automatically performed inside the label class,\n",
    "               # ImageCategoryList/ImageCategoryItem\n",
    "               #.normalize(stats = [torch.tensor([0.5,0.5,0.5]), torch.tensor([0.5,0.5,0.5])], do_x=False, do_y=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(real_images_path, batch_size, img_size, n_classes)\n",
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRITIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest method to build a BigGAN discriminator is:\n",
    "\n",
    "```\n",
    "biggan_disc_64(in_n_channels: int=3, ch_mult: int=96, **disc_kwargs)`\n",
    "```\n",
    "\n",
    "It creates an architecture with the same depth and feature maps as in the paper.\n",
    "\n",
    "The parameters `disc_kwargs` are passed through to `BigGANDiscriminator` constructor:\n",
    "\n",
    "```\n",
    "BigGANDiscriminator(in_sz: int, res_blocks_n_ftrs: List[Tuple[int, int]], \n",
    "                    idx_block_self_att: int, n_classes: int=1, \n",
    "                    down_op: core.layers.DownsamplingOperation2d=None, \n",
    "                    activ: nn.Module=None, init_func:Callable=_default_init,\n",
    "                    flatten_out=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = biggan_disc_64(img_n_channels, ch_mult, n_classes=n_classes, flatten_out=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest method to build a BigGAN generator is:\n",
    "\n",
    "```\n",
    "biggan_gen_64(out_n_channels: int=3, ch_mult: int=96, **gen_kwargs)\n",
    "```\n",
    "\n",
    "It creates an architecture with the same depth and feature maps as in the paper.\n",
    "\n",
    "The parameters `gen_kwargs` are passed through to `BigGANGenerator` constructor:\n",
    "\n",
    "```\n",
    "BigGANGenerator(out_sz: int, out_n_channels: int, up_blocks_n_ftrs: List[Tuple[int, int]], \n",
    "                z_split_sz: int=20, n_classes: int=1, class_embedding_sz: int=128, \n",
    "                up_op: core.layers.UpsamplingOperation2d=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = biggan_gen_64(img_n_channels, ch_mult, n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss, d_loss = hinge_adversarial_losses()\n",
    "g_loss_reg = loss_func_with_kernel_regularizer(g_loss, \n",
    "                                               OrthogonalRegularizer(generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = ConditionalGANLearner(data, generator, critic, GANLossArgs(g_loss, d_loss),\n",
    "                                opt_func=partial(optim.Adam, betas=(0.,0.999)), wd=0.,\n",
    "                                switch_eval=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(10, lr)\n",
    "save_gan_learner(learner, models_root/'biggan-celeba-tr1-10ep.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.show_results(ds_type=DatasetType.Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
